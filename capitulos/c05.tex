\chapter{ Testes }

Neste capítulo são apresentados os testes realizados no sistema
proposto com a arquitetura de rede neural definida no capítulo
anterior. Todos os treinamentos foram realizados na infraestrutura
citada no capítulo de proposta do trabalho. Os resultados foram
satisfatórios para o conexto do trabalho. Para produzir os gráficos
foi utilizada uma ferramenta chamada {\bf \emph{TensorBoard}}, que vem
junto com a instalação do \textit{TensorFlow}.

\section{Treinamento com 200 mil iterações}

Inicialmente realizamos um treinamento com 200 mil iterações, portanto
3.125 passos com uma carga de 64 imagens. A fase de treinamento
completa levou {\bf 1 hora 23 minutos e 54 segundos} para
completar. Deve-se salientar que para o primeiro treinamento há uma
espera maior devido ao \textit{caching} dos dados. Isso é feito pelo
sistema operacional para otimizar a memória da GPU e do sistema em
geral quando os dados são carregados para a memória volátil. 

Como é possível observar nos gráficos o valor da perda para este
treinamento oscila entre 17,02 e 17,93 até o passo número 2.050
(iteração 131.200) onde a perda começa a decair. O mesmo acontece com
a acurácia, ficando em torno de 5\% até o passo 2.050 quando começa a
subir. Ao final do treinamento foi alcançado um valor máximo de
acurácia igual a {\bf 84,38\%} no conjunto de treinamento, {\bf
  79,6\%} no conjunto de teste e um valor mínimo de perda igual a {\bf
  2,50} para o conjunto de treinamento, {\bf 2,91} para o conjunto de
teste.

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{imagens/accuracy_200k}
\caption{Gráfico da acurácia em relação ao número de passos para o
  treinamento da rede com 200 mil iterações.}
\label{fig:accuracy_200k}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{imagens/loss_200k}
\caption{Gráfico da perda em relação ao número de passos para o
  treinamento da rede com 200 mil iterações.}
\label{fig:loss_200k}
\end{figure}

Mesmo com o bom resultado nos testes, foi notado uma falta de
estabilidade nos gráficos gerados. Analisando os gráficos de desvio
padrão dos valores de pesos e \textit{biases} das últimas camadas
convolucionais, percebe-se que alguns valores poderiam continuar
alterando se o treinamento continuasse por mais iterações.

\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{imagens/stddev_200k}
\caption{Desvio padrão dos pesos e \textit{biases} em relação ao
  número de passos para o treinamento da rede com 200 mil iterações.}
\label{fig:stddev_200k}
\end{figure}

\section{Treinamento com 500 mil iterações}

Visto a instabilidade nos valores de gráficos no treinamento anterior,
a tentativa seguinte foi aumentar o número de iterações para 500 mil,
portanto 7.812 passos. O tempo total de treinamento foi de {\bf 1 hora
18 minutos e 23 segundos}.

Analisando os gráficos gerados com este treinamento, novamente o valor
da perda para oscila entre 16,87 e 17,51 até um certo ponto. Dessa vez
é no passo número 2.922 (iteração 187.008) onde a perda começa a
decair. O mesmo acontece com a acurácia, ficando em torno de 6\% até o
passo 2.977 (iteração 190.528) quando começa a subir. Ao final do
treinamento foi alcançado o valor máximo de acurácia igual a {\bf
  98,75\%} no conjunto de treinamento, {\bf 81,37\%} no conjunto de
teste e um valor mínimo de perda igual a {\bf 0,36} para o conjunto de
treinamento, {\bf 13,52} para o conjunto de teste.

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{imagens/accuracy_500k}
\caption{Gráfico da acurácia em relação ao número de passos para o
  treinamento da rede com 500 mil iterações.}
\label{fig:accuracy_500k}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{imagens/loss_500k}
\caption{Gráfico da perda em relação ao número de passos para o
  treinamento da rede com 500 mil iterações.}
\label{fig:loss_500k}
\end{figure}

Analisando os resultados, é possível observar que o valor da perda
para o conjunto de treinamento é muito diferente do valor da perda
para o conjunto de teste. Também nota-se que a acurácia no conjunto de
treinamento chegou bem perto de 100\%. De acordo com a fundamentação
teórica, esses dois fatores podem ter sido causados pelo
\textit{overfitting} do modelo ao conjunto de dados do treinamento.

\section{Treinamento com 500 mil iterações e Dropout de 50\%}

Na tentativa de minimizar os problemas encontrados anteriormente, foi
realizado um terceiro treinamento. Foi visto que uma das técnicas de
regularização para minimizar o \textit{overfitting} é adicionando uma
camada de \textit{dropout} ao modelo. Nossa arquitetura já previa uma
camada de \textit{dropout}, no entanto o parâmetro de probabilidade de
mantimento das ativações estava configurado para 75\% (0,75). Para o
terceiro treinamento foi configurada a probabilidade do
\textit{dropout} para 50\% (0,5) e assim analisados os resultados. O
tempo total de treinamento foi de {\bf 1 hora 18 minutos e 53
  segundos}.


\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{imagens/accuracy_500k_dropout50}
\caption{Gráfico da acurácia em relação ao número de passos para o
  treinamento da rede com 500 mil iterações e probabilidade de
  \textit{dropout} igual a 50\%.}
\label{fig:accuracy_500k_dropout50}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{imagens/loss_500k_dropout50}
\caption{Gráfico da perda em relação ao número de passos para o
  treinamento da rede com 500 mil iterações e probabilidade de
  \textit{dropout} igual a 50\%.}
\label{fig:loss_500k_dropout50}
\end{figure}

Ao final do treinamento foi alcançado o valor máximo de acurácia igual
a {\bf 95,31\%} no conjunto de treinamento, {\bf 92,87\%} no conjunto
de teste e um valor mínimo de perda igual a {\bf 0,93} para o conjunto
de treinamento, {\bf 1,15} para o conjunto de teste.

\section{Avaliação da acurácia em casos novos} \label{acuracia}

Com dito anteriormente na seção \ref{faseTeste}, o cálculo feito
para determinar a acurácia nos casos de teste não contemplam um acerto
completo de todas as letras em uma imagem de CAPTCHA. Por conta desse
fator e também para testar o modelo em imagens novas, foi desenvolvido
um script para carregar o modelo treinado. Esse script executa uma
sessão do modelo da mesma forma em que foi feito o treinamento na
seção \ref{treino}. A execução do teste foi mediante {\bf 18.000}
imagens novas para obter um resultado fiel a uma situação real de
reconhecimento de CAPTCHAs.

O cálculo final é simples, para cada imagem em que o modelo decifra
corretamente o texto, é incrementada uma variável {\bf acertos}. Ao
final da execução do teste para cada imagem, é dividido o número de
acertos pelo total de imagens fornecidas.

\section{Resultados}

De acordo com os testes realizados, a configuração de alguns
parâmetros no treinamento foram essenciais para eficácia do sistema
proposto.

\begin{table}[H]
\begin{center}
\begin{tabular}{|p{2.3cm}|p{2.3cm}|p{2.3cm}|p{2.3cm}|}
\hline
\textbf{} & \textbf{200k it.} & \textbf{500k it.} & \textbf{500k it. e 50\% \textit{dropout}} \\
\hline
Acurácia (teste) & {\bf 79,6\%} & {\bf 81,37\%} & {\bf 92,87\%} \\
\hline
Acurácia (treinamento) & 80,94\% & 97,81\% & 92,81\% \\
\hline
Perda (teste) & 2,91 & 13,52 & 1,15 \\
\hline
Perda (treinamento) & 2,87 & 0,43 & 1,39 \\
\hline
\end{tabular}
\caption{Desempenho geral do sistema.}
\label{tab:system_efficency}
\end{center}
\end{table}

Com a execução do script de acurácia citado na seção \ref{acuracia},
foram identificados diversos casos complexos em que o modelo teve
êxito no reconhecimento do texto completo.

\begin{figure}[H]
\centering
\includegraphics[scale=0.8]{imagens/complex_cases}
\caption{Exemplos de casos complexos em que o reconhecedor acertou o
  texto completo da imagem. Na primeira imagem é possível observar a
  semelhança entre uma letra ``g'' e o dígito ``8''. Diante da
  proximidade entre as letras da segunda imagem, o modelo poderia ter
  classificado a penúltima letra como um ``q'' ao invés do ``c'' que
  foi a letra correta. Novamente percebemos a proximidade entre as
  letras na terceira imagem. Abaixo das imagens se encontram os textos
  reconhecidos pelo modelo em cada caso respectivamente.}
\label{fig:complex_cases}
\end{figure}

Contudo também foram observados casos em que o modelo não teve sucesso
no reconhecimento do texto completo. Devido a semelhança de alguns
caractéres, o modelo reconheceu parcialmente o texto de algumas
imagens apresentadas.

\begin{figure}[H]
\centering
\includegraphics[scale=0.8]{imagens/harder_cases}
\caption{Exemplos de casos complexos em que o reconhecedor acertou
  parcialmente texto da imagem. Na primeira imagem é possível observar
  que o modelo confundiu a letra ``T'' maiúscula com um dígito ``4''.
  Na segunda imagem, mesmo com a sobreposição dos caractéres ``Q'' e
  ``r'' no meio da imagem, esses caractéres foram reconhecidos
  corretamente. Enquanto o primeiro carctere ``t'' no início da imagem
  foi erroneamente reconhecido como uma letra ``i''. Na terceira
  imagem a letra ``N'' maiúscula foi reconhecida erroneamente como uma
  letra ``x''. Abaixo das imagens se encontram os textos reconhecidos
  pelo modelo em cada caso respectivamente.}
\label{fig:harder_cases}
\end{figure}
