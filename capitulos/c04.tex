\chapter{Desenvolvimento}

Este capítulo descreve o desenvolvimento do projeto proposto. 
Para a construção e treinamento da rede neural foi implementado um
script em \textit{Python} que possui toda a arquitetura da rede
descrita de forma procedural. O framework \textit{TensorFlow} chama a
arquitetura dos modelos de \textit{Graph} (ou grafo, em português) e o
treinamento da rede neural é feito em uma \textit{Session}.

O projeto é composto por 5 tarefas de implementação: 

\begin{itemize}

\item Desenvolvimento do leitor processador do conjunto de dados.

\item Desenvolvimento da função que monta a rede neural.

\item Configuração da rede neural para otimização dos resultados.

\item Desenvolvimento da etapa de treinamento da rede neural.

\item Desenvolvimento da etapa de teste e acurácia do modelo da rede
  neural.

\end{itemize}

No início foi utilizado como base um código já existente destinado ao
reconhecimento de dígitos em imagens. A partir daí foi construído o
reconhecedor textos do trabalho.

\section{Código fonte utilizado como base} \label{codigoBase}

Como base da implementação deste trabalho, foram utilizados exemplos
de código aberto disponíveis no repositório de códigos do
\textit{TensorFlow}\cite{tensorCode}. No repositório há diversos
tutoriais e exemplos que incentivam o auto aprendizado dos
usuários. Um dos exemplos mais conhecido entre a comunidade é o
reconhecedor de dígitos da base dados MNIST\cite{mnist}.

O reconhecedor utilizado como base funciona apenas para dígitos
isolados em imagens separadas. Para o caso do trabalho em questão
foi necessário adaptá-lo para reconhecer conjuntos com 5 dígitos ou
letras em uma mesma imagem sem passar por um processo de segmentação
antes do treinamento.

\section{Leitura e pré-processamento do conjunto de dados}

Para a leitura das imagens e pré-processamento do conjunto de dados, foi
implementada uma classe chamada \textit{OCR\_data}. Esta classe utiliza
a memória RAM para armazenar o conjunto de dados enquanto é processado
pelo treinamento. Para Inicialização da classe, são necessários alguns
parâmetros:

\begin{itemize}

  \item Número de imagens que deve ser lido do disco.
  \item Diretório onde as imagens estão disponíveis.
  \item Número de classes que um caractere pode ter. Para o caso do
    trabalho esse número é igual a 36 pois cada caractere do CAPTCHA
    utilizado como exemplo pode ser somente uma letra minúscula sem
    acentos de ``a'' à ``z'' (26 letras) ou um número de ``0'' à ``9''
    (10 dígitos).
  \item Tamanho da fração dos dado para cada iteração com treinamento.
  \item Tamanho da palavra contida no CAPTCHA. 5 para nosso caso.
  \item Altura da imagem. Número fixo em 60 para as imagens disponíveis.
  \item Largura da imagem. Número fixo em 180 para as imagens
    disponíveis.
  \item Altura definida para redimensionamento da imagem.
  \item Largura definida para redimensionamento da imagem.
  \item A quantidade de canais de cor.

\end{itemize}

\subsection{Leitura das imagens}

As imagens são carregadas utilizando \textit{OpenCV}\cite{OpenCV} com
o método \textit{imread}. Após a leitura precisamos fixar o seu rótulo
para a utilização no treinamento. Como as imagens já estão nomeadas
com o respectivo conteúdo da sua imagem, só o que precisamos fazer é
um vetor utilizável desse texto. 

Primeiro transformamos cada caractere em um número de 0 à 35. Fazemos
isso recuperando o código ASCII de cada caractere e normalizando a
sequência. Portanto, para os dígitos (0 à 9) que possuem códigos indo
de 48 à 57, subtraímos 48. E para as letras (a à z) que possuem
códigos indo de 97 à 122, subtraímos 87 e ficamos com números de 10 à
35. 

Depois de traduzido o caractere para um número, precisamos criar o
vetor do rótulo através do nosso algoritmo de \textit{One-hot
  encoding}. Para isso criamos 5 vetores, um para cada caractere da
imagem, e cada vetor possui 36 posições. Completamos todas as posições
com 0 e em seguida é atribuído o número 1 para a posição referente ao
carctér. A posição do caractere foi determinada pelo passo anterior,
sendo igual o número correspondente ao caractere.

\subsubsection{Fraçao dos dados para treinamento}

Como em cada iteração do treinamento será recuperado apenas uma fração
dos dados, foi criado um método \textit{next\_batch} na classe
\textit{OCR\_data}. Outra motivação para este método é a necessidade de
recuperar uma amostra aleatória dos dados em cada iteração. 

Portanto temos uma variável global na classe \textit{OCR\_data} que
mantém o estado da posição que estamos no conjunto de dados. Após
passar por todo o conjunto de dados, nosso método começa a fazer feita
uma permutação aleatória para garantir que as posições recuperadas do
conjunto de dados sejam completamente escolhidas ao acaso.

\subsection{Pré-processamento das imagens}

Como foi dito anteriormente, a fase de pré-processamento é mínima e
requer apenas alguns parâmetros. Essa etapa é necessária para garantir
uma velocidade maior no treinamento e também garantir uma eficiência
maior como veremos a seguir.

\subsubsection{Quantidade de canais de cor}

No contexto do trabalho, não nos importamos com a cor de um caractere
da imagem. Uma letra ``A'' pode ser vermelha, azul ou verde mas ainda
terá que ser reconhecido como letra ``A''. Com isso em mente podemos
reduzir a quantidade de informações que nosso modelo precisa
aprender. É reduzido também a complexidade dos cálculos feitos pelo
modelo. Quando fazemos a leitura da imagem com a biblioteca OpenCV,
indicamos um parâmetro que diz que a imagem deve ser lida em escala de
cinza (\textit{IMREAD\_GRAYSCALE}). A escala de cinza de uma imagem
representa para cada valor de pixel uma média dos valores de cor RGB
da imagem. Para cada pixel é somado o valor de vermelho com os valores
de verde e azul e dividido por 3. Com isso podemos normalizar nossos
dados de entrada para um valor entre 0 e 1, onde 0 seria um ponto
completamente preto e 1 seria branco.

\subsubsection{Tamanho da imagem}

Outro modo de reduzir informações desnecessárias é redimensionando a
imagem. Com a biblioteca \textit{OpenCV} fazemos isso invocando a
função \textit{resize}. Nessa função passamos como parâmetro a largura
e altura alvos, assim como o algoritmo que deve ser usado para a
interpolação\footnote{Interpolação se trata do algoritmo utilizado
  para redimensionar a imagem. Esse algoritmo irá interpolar cada
  valor de pixel da imagem para obter uma nova imagem
  redimensionada.}. Foi escolhido tamanho de 88 de largura por 24 de
altura pois esses valores correspondem a mais ou menos metade da
imagem. Na seção de arquitetura da rede, também veremos que esses
valores se encaixarão mais naturalmente no nosso modelo. Como
algoritmo de interpolação foi escolhido a reamostragem utilzando a
relação da área de pixel (opção \textit{INTER\_AREA} do
\textit{OpenCV}). Este algoritmo é o indicado pela própria biblioteca
para reduzir imagens. Agora com menos dados a ser processados o
treinamento terá uma velocidade maior.

Ao final da geração de conjunto de dados criamos dois \textit{arrays}
multidimensionais com a biblioteca \textit{NumPy}. Um \textit{array} é das
imagens e terá a forma $quantidade\_de\_imagens\ x\ 88\ x\ 24\ x\ 1$,
sendo a quantidade fornecida como parâmetro, 88 x 24 a largura e
altura da imagem, e 1 é nossa quantidade de canais de cor (ou
profundidade). O outro \textit{array} é para os rótulos e terá a forma
$quantidade\_de\_imagens\ x\ 180$, sendo a quantidade fornecida como
parâmetro e 180 o tamanho do vetor do rótulo pois se trata de 36
classes possíveis multiplicado por 5 caracteres.

\section{Arquitetura da rede neural}

O desenvolvimento da arquitetura da rede neural foi realizado criando
a função \textit{ocr\_net}, que é responsável por especificar o grafo
da rede neural. Essa função irá receber as imagens de entrada, a
quantidade de pesos em cada camada e a quantidade de \textit{biases}
para cada camada.

A arquitetura implementada começa com uma camada de entrada, possui 4
camadas convolucionais, 1 camada completamente conectada e mais uma
camada completamente conectada de saída com 5 saídas, uma para cada
caractere da imagem. Entre uma e outra camada convolucional há uma
camada de ativação (ReLu) e uma camada de \textit{pooling}. Ao final
da última camada convolucional e antes da camada de saída há uma
camada de \textit{dropout}, resultando em um total de 14 camadas sendo
11 visíveis e 3 ocultas.

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{imagens/training_graph}
\caption{Arquitetura geral do modelo de rede neural treinado.}
\label{fig:training_graph}
\end{figure}

\subsection{Entradas}

Nosso grafo começa com dois parâmetros de entrada, as imagens de
entrada e os rótulos correspondentes. Para esses parâmetros criamos
\textit{placeholders} disponibilizados pelo framework. Esses
\textit{placeholders} inicialmente precisam saber qual tipo dos dados
serão inseridos e o formato final. O tipo dos dados são os valores
normalizados dos pixels das imagens portanto serão pontos
flutuantes. O formato é o que foi definido em nossa classe do conjunto
dos dados ($quantidade\_de\_imagens\ x\ 88\ x\ 24\ x\ 1$ para as
imagens e $quantidade\_de\_imagens\ x\ 180$ para os rótulos).

\subsection{Camadas}

Para melhor visualização e compreensão da arquitetura será descrita
cada camada utilizada por ordem de sequência da entrada até a saída.

\begin{enumerate}

\item Camada de entrada: um \textit{array} multidimensional de formato
  {\bf 88x24x1} que será alimentado com os valores da imagem.

\item Camada convolucional (1): tem como entrada a imagem carregada na
  camada de entrada com {\bf 1} de profundidade. Executa convoluções
  aplicadas à imagem com um \textit{kernel} de formato $5x5$ e {\bf
    64} valores de profundidade. Seu valor de \textit{stride} é igual
  a {\bf 1} e utiliza \textit{same padding}. Por fim é adicionado um
  \textit{bias} de {\bf 64} valores à convolução. O formato do \textit{array}
  multidimensional desta camada é {\bf 88x24x64}.

\item Camada oculta (1): utiliza {\bf ReLU} como função de ativação e
  não recebe nenhum parâmetro. Tem como entrada a camada convolucional
  anterior.

\item Camada de \textit{pooling} (1): executa a operação de
  \textit{max pooling} com um \textit{kernel} de formato $2x2$ e
  \textit{stride} igual a {\bf 2}. Essa operação tem como entrada a
  imagem gerada pelas convoluções após passar pela função de
  ativação. Isso irá reduzir o tamanho desta imagem pela metade. O
  formato do \textit{array} multidimensional desta camada é {\bf 44x12x64}.

\item Camada convolucional (2): tem como entrada a imagem gerada
  nas camadas anteriores com {\bf 64} de profundidade. Executa
  convoluções aplicadas à imagem com um \textit{kernel} de formato
  $5x5$ e {\bf 128} valores de profundidade. Seu valor de
  \textit{stride} é igual a {\bf 1} e utiliza \textit{same
    padding}. Por fim é adicionado um \textit{bias} de {\bf 128}
  valores à convolução. O formato do \textit{array} multidimensional desta
  camada é {\bf 44x12x128}.

\item Camada oculta (2): utiliza {\bf ReLU} como função de ativação e
  não recebe nenhum parâmetro. Tem como entrada a camada convolucional
  anterior.

\item Camada de \textit{pooling} (2): executa a operação de
  \textit{max pooling} com um \textit{kernel} de formato $2x2$ e
  \textit{stride} igual a {\bf 2}. Essa operação tem como entrada a
  imagem gerada pelas convoluções após passar pela função de
  ativação. Isso irá reduzir o tamanho desta imagem pela metade. O
  formato do \textit{array} multidimensional desta camada é {\bf 22x6x128}.

\item Camada convolucional (3): tem como entrada a imagem gerada
  nas camadas anteriores com {\bf 128} de profundidade. Executa
  convoluções aplicadas à imagem com um \textit{kernel} de formato
  $5x5$ e {\bf 256} valores de profundidade. Seu valor de
  \textit{stride} é igual a {\bf 1} e utiliza \textit{same
    padding}. Por fim é adicionado um \textit{bias} de {\bf 256}
  valores à convolução. O formato do \textit{array} multidimensional desta
  camada é {\bf 22x6x256}.

\item Camada oculta (3): utiliza {\bf ReLU} como função de ativação e
  não recebe nenhum parâmetro. Tem como entrada a camada convolucional
  anterior.

\item Camada de \textit{pooling} (2): executa a operação de
  \textit{max pooling} com um \textit{kernel} de formato $2x2$ e
  \textit{stride} igual a {\bf 2}. Essa operação tem como entrada a
  imagem gerada pelas convoluções após passar pela função de
  ativação. Isso irá reduzir o tamanho desta imagem pela metade. O
  formato do \textit{array} multidimensional desta camada é {\bf 11x3x256}.

\item Camada convolucional (4): tem como entrada a imagem gerada
  nas camadas anteriores com {\bf 256} de profundidade. Executa
  convoluções aplicadas à imagem com um \textit{kernel} de formato
  $3x3$ e {\bf 512} valores de profundidade. Seu valor de
  \textit{stride} é igual a {\bf 1} e utiliza \textit{same
    padding}. Por fim é adicionado um \textit{bias} de {\bf 512}
  valores à convolução. O formato do \textit{array} multidimensional desta
  camada é {\bf 11x3x512}.

\item Camada de \textit{dropout}: tem como entrada a camada
  convolucional anterior e possui um formato {\bf 11x3x512}. Recebe o
  valor de {\bf 0.75} como parâmetro de probabilidade de manter cada
  peso da rede neural.

\item Camada completamente conectada: tem como entrada todas as
  ativações das camadas anteriores. Para habilitar nossa camada
  completamente conectada precisamos realizar uma reformatação na
  matriz de entrada. Como a última camada possui um formato de {\bf
    11x3x512}, multiplica-se esses valores para que ao invés de
  ter uma matriz, tenha-se um vetor de tamanho {\bf 16896} como
  entrada. Assim nossa camada completamente conectada terá {\bf 16896}
  ativações de entrada e {\bf 4096} ativações de saída.

\item Camadas completamente conectadas de saída: cada camada terá como
  entrada as {\bf 4096} ativações da camada anterior. E cada saída
  será um vetor de {\bf 36} posições que corresponde às probabilidades
  de classe para cada caractere. No total serão 5 camadas paralelas
  agregadas em uma.

\end{enumerate}

\section{Configuração da rede neural}

Parâmetros fornecidos para a configuração do treinamento da rede
neural são chamados de {\bf hiperparâmetros}. Dependendo da
arquitetura utilizada, uma rede neural pode ter uma quantidade
diferente de hiperparâmetros. A maioria dos hiperparâmetros utilizados
no trabalho foram indicados em artigos citados ao longo da sessão, ou
vieram dos exemplos e tutoriais citados na seção
\ref{codigoBase}. Alguns parâmetros foram modificados ao longo dos
testes.

\subsection{Quantidade de ativações}

Os números de ativações 64, 128, 256, 512 e 4096 nas saídas das
camadas foram utilizados com base em estudos anteriores feitos sobre
redes convolucionais\cite{Krizhevsky}.

\subsection{Tamanho do Kernel}

Baseado nos estudos de \cite{Goodfellow}, foi escolhido um formato
de $5x5$ para o tamanho do \textit{kernel} para a maioria das
camadas. Para a última camada convolucional foi escolhido o tamanho
de $3x3$ pois o \textit{kernel} não pode ter uma dimensão maior que
a imagem de entrada. Como na última camada recebemos uma imagem no
formato $11x3$, não é possivel aplicar convoluções de tamanho $5x5$.

\subsection{Parâmetros do declínio exponencial da taxa de aprendizado}

Ao utilizar uma taxa de aprendizado decadente no otimizador, são
fornecidos alguns parâmetros relativos ao processo de decadência da
taxa. Os valores fornecidos tem como base um dos treinamentos de rede
neural disponível em \cite{tensorCode}.

\begin{itemize}
  
  \item {\bf taxa de aprendizado inicial
      (\emph{initial\_learning\_rate}):} é fornecido um valor de
    {\bf 0,01} para a taxa de aprendizado no início do treinamento.

  \item {\bf passos para decair (\emph{decay\_steps}):} valor que
    indica a cada quantos passos a taxa de aprendizado deve
    diminuir. Esse valor é de {\bf 1.000} passos para o caso do
    trabalho.

  \item {\bf taxa de decadência (\emph{decay\_rate}):} valor referente
    ao quanto a taxa de aprendizado deve decair. Foi escolhido {\bf
      0,9} para o caso do trabalho, portanto a taxa de aprendizado vai
    cair 10\% a cada 1.000 passos do treinamento.

\end{itemize}

\subsection{Momentum}

A estratégia de \textit{momentum} de nosso treinamento precisa de uma
variável que será o fator determinante para o cálculo do gradiente. O
valor dessa variável recomendado pela maioria dos estudos e exemplos é
igual a {\bf 0,9} e é o valor utilizado no treinamento proposto.

\subsection{Regularização com $L_2$}

Como foi dito no capítulo de fundamentação teórica, um parâmetro de
regularização pode ser adicionado a perda do treinamento. Além da
norma $L_2$ calculada baseada nos pesos, esse valor é multiplicado por
uma variável $\beta$ que tem valor igual a {\bf 0,0003} para o
treinamento feito neste trabalho.

\subsection{Probabilidade do Dropout}

Cada valor das ativações terá uma probabilidade de ser mantido ou
não. Como já foi contemplado na explicação do \textit{dropout}, cada
ativação pode ser removida entre uma camada e outra. Para os
treinamentos realizados, foram utilizados dois valores como
tentativa. O primeiro valor foi de {\bf 0,75} e o segundo foi {\bf
  0,5}, isso dá 75\% e 50\% das ativações mantidas respectivamente. O
segundo valor foi empregado na tentativa de minimizar o problema de
\textit{overfitting}.

\subsection{Tamanho da carga em cada passo}

Na otimização com SGD é fornecido um pedaço do conjunto de dados
total em cada passo que calcula-se o método do gradiente. Este pedaço
dos dados será chamado de ``carga'' (ou \textit{batch} em inglês) para
o presente contexto. Baseado em exemplos anteriores, foi escolhido um
valor de {\bf 64} imagens para o tamanho de carga.

\subsection{Número de iterações}

O número de iterações consiste basicamente na quantidade de exemplos
que será calculado o gradiente. Este número leva em consideração o
tamanho da carga e dá o resultado do número de passos que serão
executados no treinamento. Para os treinamentos realizados neste
trabalho foram escolhidos dois valores, um com {\bf 200 mil} iterações
outro com {\bf 500 mil} iterações. Portanto para um treinamento
haverá {\bf 3.125} ($200.000 / 64$) passos e para os outros haverá
{\bf 7.812} ($500.000 / 64$) passos.

\section{Fase de treinamento} \label{treino}

A fase de treinamento é o momento onde se junta todas as peças da
arquitetura e configuração da rede neural. Na implementação foi
criada uma função \textit{train} que é responsável por montar de fato
o grafo para a rede e utilizar o objeto \textit{Session} do
\textit{TensorFlow} para o treinamento.

\subsection{Criação da sessão de treinamento}

O desenvolvimento começa com a abertura da sessão de treinamento. Esta
sessão será destruída ao final das iterações para limpar todas as
variáveis de treinamento carregadas em memória. Após a abertura da
sessão é chamada a função \textit{ocr\_net} para que seja instanciada a
arquitetura da rede neural. Todas as variáveis instanciadas até o
momento de execução da sessão são apenas espaços reservados, assim
como os \textit{placeholders} criados para os dados de entrada do
modelo. Com a arquitetura em mãos será calculada a perda, realizando
uma soma das perdas para cada caractere de saída da rede neural. Em
seguida é instanciado o otimizador (\textit{MomentumOptimizer}) e por
final as predições são agregadas em uma matriz transposta para que
fiquem com o formato $5x36$ (5 caractéres por 36 classes).

\subsection{Inicialização da sessão de treinamento}

Para inicializar a sessão de treinamento é invocado o método
\textit{initialize\_all\_variables} para popular os espaços reservados
das variáveis. Com isso é possível executar a sessão pela primeira vez
invocando \textit{session.run} passando como parâmetro o retorno de
\textit{initialize\_all\_variables}.

\subsection{Execução da sessão de treinamento}

Para manter o controle do treinamento é criada uma variável
\textit{step} que irá manter o estado da quantidade de passos
executados em cada execução da sessão. Para cada passo é invocado o
método \textit{next\_batch} da instância da classe \textit{OCR\_data}
referente ao treinamento. Também será invocado \textit{session.run}
passando como parâmetro o otimizador e carga de dados através de um
dicionário chamado \textit{feed\_dict}. Esse dicionário receberá o
retorno do método \textit{next\_batch} e com isso é possível popular
os \textit{placeholders} da carga de imagens e de seus respectivos
rótulos.

Em cada passo executado é calculada a perda para o treinamento. E a
cada 100 passos é calculada a acurácia para a sessão de treinamento. A
execução do treinamento fica em ciclos até que o número de passos
multiplicado pela quantidade de carga (64) seja igual ao número de
iterações (200 mil ou 500 mil). Ao final de todas as iterações é
instanciado um \textit{Saver}, o qual fará a escrita das variáveis de
nosso modelo em um arquivo. Este arquivo será utilizado para a
avaliação da acurácia em situações reais.

\section{Fase de teste} \label{faseTeste}

A implementação da fase de teste consiste na execução de apenas um
passo da sessão aberta na seção \ref{treino}. Ao final da otimização
do modelo, é carregado o conjunto de imagens para teste, assim como os
respectivos rótulos. A carga é feita utilizando o método
\textit{next\_batch} da instância da classe \textit{OCR\_data}
referente ao teste. Com isso é possível popular o dicionário
\textit{feed\_dict} da sessão de teste e executar \textit{session.run}
com este parâmetro. Ao final teremos o valor da acurácia e da perda
para o conjunto de dados do teste.

\subsection{Acurácia}

O cálculo da acurácia para o modelo é o mesmo tanto para a fase de
treinamento quanto para fase de teste. A função de acurácia recebe
como parâmetro a matriz de predições gerada pelo modelo e a matriz de
rótulos fornecida pela carga dos dados. O cálculo é feito armazenando o
maior valor de cada \textit{array} da matriz de predições e comparando
as posições desses valores com as posiçõs da matriz de rótulos. A
acurácia sobe para cada letra certa em uma imagem de CAPTCHA, sem
levar em consideração se todas as letras estão certas ou não.

