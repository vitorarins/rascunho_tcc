\chapter{Desenvolvimento e Testes}

Este capítulo descreve o desenvolvimento do projeto proposto. O
projeto é composto da implementação do processador do conjunto de
dados, da implementação do script que monta e treina a rede neural e
da configuração da rede neural para otimização dos resultados. No
início foi utilizado como base um código já existente destinado ao
reconhecimento de dígitos em imagens. A partir daí foi construído o
reconhecedor textos do trabalho.

\section{Código fonte utilizado como base}

Como base da implementação deste trabalho, foi utilizado um exemplo
de código aberto disponível no repositório de códigos do
\textit{TensorFlow}\cite{mnistCode}. O código em questão seria para
reconhecer os dígitos da base dados MNIST\cite{mnist}.

O reconhecedor utilizado como base funciona apenas para dígitos
isolados em imagens separadas. Para o caso do trabalho em questões
precisaremos adaptá-lo para reconhecer conjuntos com 5 dígitos ou
letras em uma mesma imagem sem passar por um processo de segmentação
antes do treinamento.

\section{Leitura e pré-processamento do conjunto de dados}

Para a leitura das imagens e pré-processamento do conjunto de dados, foi
implementada uma classe chamada \textit{OCR\_data}. Esta classe utiliza
a memória RAM para armazenar o conjunto de dados enquanto é processado
pelo treinamento. Para Inicialização da classe, são necessários alguns
parâmetros:

\begin{itemize}

  \item Número de imagens que deve ser lido do disco.
  \item Diretório onde as imagens estão disponíveis.
  \item Número de classes que um caractér pode ter. Para o caso do
    trabalho esse número é igual a 36 pois cada caractér do CAPTCHA
    utilizado como exemplo pode ser somente uma letra minúscula sem
    acentos de ``a'' à ``z'' (26 letras) ou um número de ``0'' à ``9''
    (10 dígitos).
  \item Tamanho da fração dos dado para cada iteração com treinamento.
  \item Tamanho da palavra contida no CAPTCHA. 5 para nosso caso.
  \item Altura da imagem. Número fixo em 60 para as imagens disponíveis.
  \item Largura da imagem. Número fixo em 180 para as imagens
    disponíveis.
  \item Altura definida para redimensionamento da imagem.
  \item Largura definida para redimensionamento da imagem.
  \item A quantidade de canais de cor.

\end{itemize}

\subsection{Leitura das imagens}

As imagens são carregadas utilizando \textit{OpenCV}\cite{OpenCV} com
o método \textit{imread}. Após a leitura precisamos fixar o seu rótulo
para a utilização no treinamento. Como as imagens já estão nomeadas
com o respectivo conteúdo da sua imagem, só o que precisamos fazer é
um vetor utilizável desse texto. 

Primeiro transformamos cada caractér em um número de 0 à 35. Fazemos
isso recuperando o código ASCII de cada caractér e normalizando a
sequência. Portanto, para os dígitos (0 à 9) que possuem códigos indo
de 48 à 57, subtraímos 48. E para as letras (a à z) que possuem
códigos indo de 97 à 122, subtraímos 87 e ficamos com números de 10 à
35. 

Depois de traduzido o caractér para um número, precisamos criar o
vetor do rótulo através do nosso algoritmo de \textit{One-hot
  encoding}. Para isso criamos 5 vetores, um para cada caractér da
imagem, e cada vetor possui 36 posições. Completamos todas as posições
com 0 e em seguida é atribuído o número 1 para a posição referente ao
carctér. A posição do caractér foi determinada pelo passo anterior,
sendo igual o número correspondente ao caractér.

\subsubsection{Fraçao dos dados para treinamento}

Como em cada iteração do treinamento será recuperado apenas uma fração
dos dados, foi criado um método \textit{next\_batch} na classe
\textit{OCR\_data}. Outra motivação para este método é a necessidade de
recuperar uma amostra aleatória dos dados em cada iteração. 

Portanto temos uma variável global na classe \textit{OCR\_data} que
mantém o estado da posição que estamos no conjunto de dados. Após
passar por todo o conjunto de dados, nosso método começa a fazer feita
uma permutação aleatória para garantir que as posições recuperadas do
conjunto de dados sejam completamente escolhidas ao acaso.

\subsection{Pré-processamento das imagens}

Como foi dito anteriormente, a fase de pré-processamento é mínima e
requer apenas alguns parâmetros. Essa etapa é necessária para garantir
uma velocidade maior no treinamento e também garantir uma eficiência
maior como veremos a seguir.

\subsubsection{Quantidade de canais de cor}

No contexto do trabalho, não nos importamos com a cor de um caractér
da imagem. Uma letra ``A'' pode ser vermelha, azul ou verde mas ainda
terá que ser reconhecido como letra ``A''. Com isso em mente podemos
reduzir a quantidade de informações que nosso modelo precisa
aprender. É reduzido também a complexidade dos cálculos feitos pelo
modelo. Quando fazemos a leitura da imagem com a biblioteca OpenCV,
indicamos um parâmetro que diz que a imagem deve ser lida em escala de
cinza (\textit{IMREAD\_GRAYSCALE}). A escala de cinza de uma imagem
representa para cada valor de pixel uma média dos valores de cor RGB
da imagem. Para cada pixel é somado o valor de vermelho com os valores
de verde e azul e dividido por 3. Com isso podemos normalizar nossos
dados de entrada para um valor entre 0 e 1, onde 0 seria um ponto
completamente preto e 1 seria branco.

\subsubsection{Tamanho da imagem}

Outro modo de reduzir informações desnecessárias é redimensionando a
imagem. Com a biblioteca \textit{OpenCV} fazemos isso invocando a
função \textit{resize}. Nessa função passamos como parâmetro a largura
e altura alvos, assim como o algoritmo que deve ser usado para a
interpolação\footnote{Interpolação se trata do algoritmo utilizado
  para redimensionar a imagem. Esse algoritmo irá interpolar cada
  valor de pixel da imagem para obter uma nova imagem
  redimensionada.}. Foi escolhido tamanho de 88 de largura por 24 de
altura pois esses valores correspondem a mais ou menos metade da
imagem. Na seção de arquitetura da rede, também veremos que esses
valores se encaixarão mais naturalmente no nosso modelo. Como
algoritmo de interpolação foi escolhido a reamostragem utilzando a
relação da área de pixel (opção \textit{INTER\_AREA} do
\textit{OpenCV}). Este algoritmo é o indicado pela própria biblioteca
para reduzir imagens. Agora com menos dados a ser processados o
treinamento terá uma velocidade maior.

Ao final da geração de conjunto de dados criamos dois arrays
multidimencionais com a biblioteca \textit{NumPy}. Um array é das
imagens e terá a forma $quantidade\_de\_imagens\ x\ 88\ x\ 24\ x\ 1$,
sendo a quantidade fornecida como parâmetro, 88 x 24 a largura e
altura da imagem, e 1 é nossa quantidade de canais de cor (ou
profundidade). O outro array é para os rótulos e terá a forma
$quantidade\_de\_imagens\ x\ 180$, sendo a quantidade fornecida como
parâmetro e 180 o tamanho do vetor do rótulo pois se trata de 36
classes possíveis multiplicado por 5 caractéres.

\section{Construção da rede neural}