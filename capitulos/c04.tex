\chapter{Desenvolvimento}

Este capítulo descreve o desenvolvimento do projeto proposto. O
projeto é composto da implementação do processador do conjunto de
dados, da implementação do script que monta e treina a rede neural e
da configuração da rede neural para otimização dos resultados. No
início foi utilizado como base um código já existente destinado ao
reconhecimento de dígitos em imagens. A partir daí foi construído o
reconhecedor textos do trabalho.

\section{Código fonte utilizado como base}

Como base da implementação deste trabalho, foram utilizados exemplos
de código aberto disponíveis no repositório de códigos do
\textit{TensorFlow}\cite{tensorCode}. No repositório há diversos
tutoriais e exemplos que incentivam o auto aprendizado dos
usuários. Um dos exemplos mais conhecido entre a comunidade é o
reconhecedor de dígitos da base dados MNIST\cite{mnist}.

O reconhecedor utilizado como base funciona apenas para dígitos
isolados em imagens separadas. Para o caso do trabalho em questão
foi necessário adaptá-lo para reconhecer conjuntos com 5 dígitos ou
letras em uma mesma imagem sem passar por um processo de segmentação
antes do treinamento.

\section{Leitura e pré-processamento do conjunto de dados}

Para a leitura das imagens e pré-processamento do conjunto de dados, foi
implementada uma classe chamada \textit{OCR\_data}. Esta classe utiliza
a memória RAM para armazenar o conjunto de dados enquanto é processado
pelo treinamento. Para Inicialização da classe, são necessários alguns
parâmetros:

\begin{itemize}

  \item Número de imagens que deve ser lido do disco.
  \item Diretório onde as imagens estão disponíveis.
  \item Número de classes que um caractere pode ter. Para o caso do
    trabalho esse número é igual a 36 pois cada caractere do CAPTCHA
    utilizado como exemplo pode ser somente uma letra minúscula sem
    acentos de ``a'' à ``z'' (26 letras) ou um número de ``0'' à ``9''
    (10 dígitos).
  \item Tamanho da fração dos dado para cada iteração com treinamento.
  \item Tamanho da palavra contida no CAPTCHA. 5 para nosso caso.
  \item Altura da imagem. Número fixo em 60 para as imagens disponíveis.
  \item Largura da imagem. Número fixo em 180 para as imagens
    disponíveis.
  \item Altura definida para redimensionamento da imagem.
  \item Largura definida para redimensionamento da imagem.
  \item A quantidade de canais de cor.

\end{itemize}

\subsection{Leitura das imagens}

As imagens são carregadas utilizando \textit{OpenCV}\cite{OpenCV} com
o método \textit{imread}. Após a leitura precisamos fixar o seu rótulo
para a utilização no treinamento. Como as imagens já estão nomeadas
com o respectivo conteúdo da sua imagem, só o que precisamos fazer é
um vetor utilizável desse texto. 

Primeiro transformamos cada caractere em um número de 0 à 35. Fazemos
isso recuperando o código ASCII de cada caractere e normalizando a
sequência. Portanto, para os dígitos (0 à 9) que possuem códigos indo
de 48 à 57, subtraímos 48. E para as letras (a à z) que possuem
códigos indo de 97 à 122, subtraímos 87 e ficamos com números de 10 à
35. 

Depois de traduzido o caractere para um número, precisamos criar o
vetor do rótulo através do nosso algoritmo de \textit{One-hot
  encoding}. Para isso criamos 5 vetores, um para cada caractere da
imagem, e cada vetor possui 36 posições. Completamos todas as posições
com 0 e em seguida é atribuído o número 1 para a posição referente ao
carctér. A posição do caractere foi determinada pelo passo anterior,
sendo igual o número correspondente ao caractere.

\subsubsection{Fraçao dos dados para treinamento}

Como em cada iteração do treinamento será recuperado apenas uma fração
dos dados, foi criado um método \textit{next\_batch} na classe
\textit{OCR\_data}. Outra motivação para este método é a necessidade de
recuperar uma amostra aleatória dos dados em cada iteração. 

Portanto temos uma variável global na classe \textit{OCR\_data} que
mantém o estado da posição que estamos no conjunto de dados. Após
passar por todo o conjunto de dados, nosso método começa a fazer feita
uma permutação aleatória para garantir que as posições recuperadas do
conjunto de dados sejam completamente escolhidas ao acaso.

\subsection{Pré-processamento das imagens}

Como foi dito anteriormente, a fase de pré-processamento é mínima e
requer apenas alguns parâmetros. Essa etapa é necessária para garantir
uma velocidade maior no treinamento e também garantir uma eficiência
maior como veremos a seguir.

\subsubsection{Quantidade de canais de cor}

No contexto do trabalho, não nos importamos com a cor de um caractere
da imagem. Uma letra ``A'' pode ser vermelha, azul ou verde mas ainda
terá que ser reconhecido como letra ``A''. Com isso em mente podemos
reduzir a quantidade de informações que nosso modelo precisa
aprender. É reduzido também a complexidade dos cálculos feitos pelo
modelo. Quando fazemos a leitura da imagem com a biblioteca OpenCV,
indicamos um parâmetro que diz que a imagem deve ser lida em escala de
cinza (\textit{IMREAD\_GRAYSCALE}). A escala de cinza de uma imagem
representa para cada valor de pixel uma média dos valores de cor RGB
da imagem. Para cada pixel é somado o valor de vermelho com os valores
de verde e azul e dividido por 3. Com isso podemos normalizar nossos
dados de entrada para um valor entre 0 e 1, onde 0 seria um ponto
completamente preto e 1 seria branco.

\subsubsection{Tamanho da imagem}

Outro modo de reduzir informações desnecessárias é redimensionando a
imagem. Com a biblioteca \textit{OpenCV} fazemos isso invocando a
função \textit{resize}. Nessa função passamos como parâmetro a largura
e altura alvos, assim como o algoritmo que deve ser usado para a
interpolação\footnote{Interpolação se trata do algoritmo utilizado
  para redimensionar a imagem. Esse algoritmo irá interpolar cada
  valor de pixel da imagem para obter uma nova imagem
  redimensionada.}. Foi escolhido tamanho de 88 de largura por 24 de
altura pois esses valores correspondem a mais ou menos metade da
imagem. Na seção de arquitetura da rede, também veremos que esses
valores se encaixarão mais naturalmente no nosso modelo. Como
algoritmo de interpolação foi escolhido a reamostragem utilzando a
relação da área de pixel (opção \textit{INTER\_AREA} do
\textit{OpenCV}). Este algoritmo é o indicado pela própria biblioteca
para reduzir imagens. Agora com menos dados a ser processados o
treinamento terá uma velocidade maior.

Ao final da geração de conjunto de dados criamos dois arrays
multidimensionais com a biblioteca \textit{NumPy}. Um array é das
imagens e terá a forma $quantidade\_de\_imagens\ x\ 88\ x\ 24\ x\ 1$,
sendo a quantidade fornecida como parâmetro, 88 x 24 a largura e
altura da imagem, e 1 é nossa quantidade de canais de cor (ou
profundidade). O outro array é para os rótulos e terá a forma
$quantidade\_de\_imagens\ x\ 180$, sendo a quantidade fornecida como
parâmetro e 180 o tamanho do vetor do rótulo pois se trata de 36
classes possíveis multiplicado por 5 caracteres.

\section{Arquitetura da rede neural}

Para a construção e treinamento da rede neural foi implementado um
script em \textit{Python} que possui toda a arquitetura da rede
descrita de forma procedural. O framework \textit{TensorFlow} chama a
arquitetura dos modelos de \textit{Graph} (ou grafo, em português).

A arquitetura implementada começa com uma camada de entrada, possui 4
camadas convolucionais, 1 camada completamente conectada e mais uma
camada completamente conectada de saída com 5 saídas, uma para cada
caractere da imagem. Entre uma e outra camada convolucional há uma
camada de ativação (ReLu) e uma camada de \textit{pooling}. Ao final
da última camada convolucional e antes da camada de saída há uma
camada de \textit{dropout}, resultando em um total de 14 camadas sendo
11 visíveis e 3 ocultas.

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{imagens/training_graph}
\caption{Arquitetura geral do modelo de rede neural treinado.}
\label{fig:gradient_descent}
\end{figure}

\subsection{Entradas}

Nosso grafo começa com dois parâmetros de entrada, as imagens de
entrada e os rótulos correspondentes. Para esses parâmetros criamos
\textit{placeholders} disponibilizados pelo framework. Esses
\textit{placeholders} inicialmente precisam saber qual tipo dos dados
serão inseridos e o formato final. O tipo dos dados são os valores
normalizados dos pixels das imagens portanto serão pontos
flutuantes. O formato é o que foi definido em nossa classe do conjunto
dos dados ($quantidade\_de\_imagens\ x\ 88\ x\ 24\ x\ 1$ para as
imagens e $quantidade\_de\_imagens\ x\ 180$ para os rótulos).

\subsection{Camadas}

Para melhor visualização e compreensão da arquitetura será descrita
cada camada utilizada por ordem de sequência da entrada até a saída.

\begin{enumerate}

\item Camada de entrada: um array multidimensional de formato
  {\bf 88x24x1} que será alimentado com os valores da imagem.

\item Camada convolucional (1): tem como entrada a imagem carregada na
  camada de entrada com {\bf 1} de profundidade. Executa convoluções
  aplicadas à imagem com um \textit{kernel} de formato $5x5$ e {\bf
    64} valores de profundidade. Seu valor de \textit{stride} é igual
  a {\bf 1} e utiliza \textit{same padding}. Por fim é adicionado um
  \textit{bias} de {\bf 64} valores à convolução. O formato do array
  multidimensional desta camada é {\bf 88x24x64}.

\item Camada oculta (1): utiliza {\bf ReLU} como função de ativação e
  não recebe nenhum parâmetro. Tem como entrada a camada convolucional
  anterior.

\item Camada de \textit{pooling} (1): executa a operação de
  \textit{max pooling} com um \textit{kernel} de formato $2x2$ e
  \textit{stride} igual a {\bf 2}. Essa operação tem como entrada a
  imagem gerada pelas convoluções após passar pela função de
  ativação. Isso irá reduzir o tamanho desta imagem pela metade. O
  formato do array multidimensional desta camada é {\bf 44x12x64}.

\item Camada convolucional (2): tem como entrada a imagem gerada
  nas camadas anteriores com {\bf 64} de profundidade. Executa
  convoluções aplicadas à imagem com um \textit{kernel} de formato
  $5x5$ e {\bf 128} valores de profundidade. Seu valor de
  \textit{stride} é igual a {\bf 1} e utiliza \textit{same
    padding}. Por fim é adicionado um \textit{bias} de {\bf 128}
  valores à convolução. O formato do array multidimensional desta
  camada é {\bf 44x12x128}.

\item Camada oculta (2): utiliza {\bf ReLU} como função de ativação e
  não recebe nenhum parâmetro. Tem como entrada a camada convolucional
  anterior.

\item Camada de \textit{pooling} (2): executa a operação de
  \textit{max pooling} com um \textit{kernel} de formato $2x2$ e
  \textit{stride} igual a {\bf 2}. Essa operação tem como entrada a
  imagem gerada pelas convoluções após passar pela função de
  ativação. Isso irá reduzir o tamanho desta imagem pela metade. O
  formato do array multidimensional desta camada é {\bf 22x6x128}.

\item Camada convolucional (3): tem como entrada a imagem gerada
  nas camadas anteriores com {\bf 128} de profundidade. Executa
  convoluções aplicadas à imagem com um \textit{kernel} de formato
  $5x5$ e {\bf 256} valores de profundidade. Seu valor de
  \textit{stride} é igual a {\bf 1} e utiliza \textit{same
    padding}. Por fim é adicionado um \textit{bias} de {\bf 256}
  valores à convolução. O formato do array multidimensional desta
  camada é {\bf 22x6x256}.

\item Camada oculta (3): utiliza {\bf ReLU} como função de ativação e
  não recebe nenhum parâmetro. Tem como entrada a camada convolucional
  anterior.

\item Camada de \textit{pooling} (2): executa a operação de
  \textit{max pooling} com um \textit{kernel} de formato $2x2$ e
  \textit{stride} igual a {\bf 2}. Essa operação tem como entrada a
  imagem gerada pelas convoluções após passar pela função de
  ativação. Isso irá reduzir o tamanho desta imagem pela metade. O
  formato do array multidimensional desta camada é {\bf 11x3x256}.

\item Camada convolucional (4): tem como entrada a imagem gerada
  nas camadas anteriores com {\bf 256} de profundidade. Executa
  convoluções aplicadas à imagem com um \textit{kernel} de formato
  $3x3$ e {\bf 512} valores de profundidade. Seu valor de
  \textit{stride} é igual a {\bf 1} e utiliza \textit{same
    padding}. Por fim é adicionado um \textit{bias} de {\bf 512}
  valores à convolução. O formato do array multidimensional desta
  camada é {\bf 11x3x512}.

\item Camada de \textit{dropout}: tem como entrada a camada
  convolucional anterior e possui um formato {\bf 11x3x512}. Recebe o
  valor de {\bf 0.75} como parâmetro de probabilidade de manter cada
  peso da rede neural.

\item Camada completamente conectada: tem como entrada todas as
  ativações das camadas anteriores. Para habilitar nossa camada
  completamente conectada precisamos realizar uma reformatação na
  matriz de entrada. Como a última camada possui um formato de {\bf
    11x3x512}, multiplica-se esses valores para que ao invés de
  ter uma matriz, tenha-se um vetor de tamanho {\bf 16896} como
  entrada. Assim nossa camada completamente conectada terá {\bf 16896}
  ativações de entrada e {\bf 4096} ativações de saída.

\item Camadas completamente conectadas de saída: cada camada terá como
  entrada as {\bf 4096} ativações da camada anterior. E cada saída
  será um vetor de {\bf 36} posições que corresponde às probabilidades
  de classe para cada caractere. No total serão 5 camadas paralelas
  agregadas em uma.

\end{enumerate}

\section{Configuração da rede neural}

Parâmetros fornecidos para a configuração do treinamento da rede
neural são chamados de {\bf hiperparâmetros}. Dependendo da
arquitetura utilizada, uma rede neural pode ter uma quantidade
diferente de hiperparâmetros. A maioria dos hiperparâmetros utilizados
no trabalho foram indicados artigos e trabalhos publicados sobre redes
neurais convolucionais. Outro fator levado em consideração é a
experiência do autor em relação ao tema em outras ocasiões.

\subsection{Quantidade de ativações}

Os números de ativações 64, 128, 256, 512 e 4096 nas saídas das
camadas foram utilizados com base em estudos anteriores feitos sobre
redes convolucionais\cite{Krizhevsky}.

\subsection{Tamanho do Kernel}

Baseado nos estudos de \cite{Goodfellow}, foi escolhido um formato
de $5x5$ para o tamanho do \textit{kernel} para a maioria das
camadas. Para a última camada convolucional foi escolhido o tamanho
de $3x3$ pois o \textit{kernel} não pode ter uma dimensão maior que
a imagem de entrada. Como na última camada recebemos uma imagem no
formato $11x3$, não é possivel aplicar convoluções de tamanho $5x5$.

\subsection{Parâmetros do declínio exponencial da taxa de aprendizado}

Ao utilizar uma taxa de aprendizado decadente no otimizador, são
fornecidos alguns parâmetros relativos ao processo de decadência da
taxa. Os valores fornecidos tem como base um dos treinamentos de rede
neural disponível em \cite{tensorCode}.

\begin{itemize}
  
  \item {\bf taxa de aprendizado inicial
      (\emph{initial\_learning\_rate}):} é fornecido um valor de
    {\bf 0,01} para a taxa de aprendizado no início do treinamento.

  \item {\bf passos para decair (\emph{decay\_steps}):} valor que
    indica a cada quantos passos a taxa de aprendizado deve
    diminuir. Esse valor é de {\bf 1.000} passos para o caso do
    trabalho.

  \item {\bf taxa de decadência (\emph{decay\_rate}):} valor referente
    ao quanto a taxa de aprendizado deve decair. Foi escolhido {\bf
      0,9} para o caso do trabalho, portanto a taxa de aprendizado vai
    cair 10\% a cada 1.000 passos do treinamento.

\end{itemize}

\subsection{Momentum}

A estratégia de \textit{momentum} de nosso treinamento precisa de uma
variável que será o fator determinante para o cálculo do gradiente. O
valor dessa variável recomendado pela maioria dos estudos e exemplos é
igual a {\bf 0,9} e é o valor utilizado no treinamento proposto.

\subsection{Regularização com $L_2$}

Como foi dito no capítulo de fundamentação teórica, um parâmetro de
regularização pode ser adicionado a perda do treinamento. Além da
norma $L_2$ calculada baseada nos pesos, esse valor é multiplicado por
uma variável $\beta$ que tem valor igual a {\bf 0,0003} para o
treinamento feito neste trabalho.

\subsection{Probabilidade do Dropout}

Cada valor das ativações terá uma probabilidade de ser mantido ou
não. Como já foi contemplado na explicação do \textit{dropout}, cada
ativação pode ser removida entre uma camada e outra. Para os
treinamentos realizados, foram utilizados dois valores como
tentativa. O primeiro valor foi de {\bf 0,75} e o segundo foi {\bf
  0,5}, isso dá 75\% e 50\% das ativações mantidas respectivamente. O
segundo valor foi empregado na tentativa de minimizar o problema de
\textit{overfitting}.

\subsection{Tamanho da carga em cada passo}

Na otimização com SGD é fornecido um pedaço do conjunto de dados
total em cada passo que calcula-se o método do gradiente. Este pedaço
dos dados será chamado de ``carga'' (ou \textit{batch} em inglês) para
o presente contexto. Baseado em exemplos anteriores, foi escolhido um
valor de {\bf 64} imagens para o tamanho de carga.

\subsection{Número de iterações}

O número de iterações consiste basicamente na quantidade de exemplos
que será calculado o gradiente. Este número leva em consideração o
tamanho da carga e dá o resultado do número de passos que serão
executados no treinamento. Para os treinamentos realizados neste
trabalho foram escolhidos dois valores, um com {\bf 200 mil} iterações
outro com {\bf 500 mil} iterações. Portanto para um treinamento
haverá {\bf 3.125} ($200.000 / 64$) passos e para os outros haverá
{\bf 7.812} ($500.000 / 64$) passos.

